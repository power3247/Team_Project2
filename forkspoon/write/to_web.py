# -*- coding: utf-8 -*-
"""to_web.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/github/yoonputer/Team_Project2/blob/master/Deeplearning/to_web.ipynb
"""

import numpy as np
from konlpy.tag import Mecab
import konlpy
import pickle
import tensorflow as tf
!ls ./drive/MyDrive/Forkspoon/tok_index_word.pkl

!python - m pip install konlpy

!curl - O https: // raw.githubusercontent.com/konlpy/konlpy/master/scripts/mecab.sh

!source ./mecab.sh


model = tf.keras.models.load_model(
    './drive/MyDrive/Forkspoon/test_dummy_LSTM.h5')
print(model)

stopwords = pickle.load(
    open('./drive/MyDrive/Forkspoon/tok_index_word.pkl', 'rb'))
print(stopwords)

mecab = Mecab()

input_sentance = mecab.morphs('성실합니다')
input_sentance = [tok for tok in input_sentance if tok not in stopwords]
print(input_sentance)

tokenizer = pickle.load(open('./drive/MyDrive/Forkspoon/tokenizers.pkl', 'rb'))

vocb_size = len(tokenizer.word_index)
vocb_size

encoded = tokenizer.texts_to_sequences([input_sentance])
encoded

pad_new = tf.keras.preprocessing.sequence.pad_sequences(encoded, maxlen=300)
pad_new

score = model.predict(pad_new)
score


np.argmax(score)

"""## 함수로 만들기"""


def sentance_predict(sentence):
    mecab = Mecab()
    input_sentance = mecab.morphs(sentence)
    input_sentance = [tok for tok in input_sentance if tok not in stopwords]
    encoded = tokenizer.texts_to_sequences([input_sentance])
    pad_new = tf.keras.preprocessing.sequence.pad_sequences(
        encoded, maxlen=300)
    score = model.predict(pad_new)
    return score


sentencess = '성실하네요'
sentance_predict(sentencess)
